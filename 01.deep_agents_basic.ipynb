{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Agents with LangChain\n",
    "\n",
    "This notebook demonstrates how to create and use Deep Agents with LangChain.\n",
    "\n",
    "Deep Agents are more sophisticated than basic ReAct agents. They:\n",
    "- Can handle complex, multi-step tasks\n",
    "- Maintain state across multiple interactions\n",
    "- Use memory to recall previous interactions\n",
    "- Can decompose complex problems into subtasks\n",
    "\n",
    "## What You'll Learn:\n",
    "- Building agents with memory\n",
    "- Creating agent chains for complex workflows\n",
    "- Using conversation history\n",
    "- Implementing reflection and self-correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_openai_functions_agent, AgentExecutor\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain import hub\n",
    "\n",
    "# Import our custom tools\n",
    "from tools.tavily_search import get_tavily_search_tool\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"âœ“ Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set Up API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and set your API keys if not using .env file\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\"\n",
    "# os.environ[\"TAVILY_API_KEY\"] = \"your-tavily-api-key\"\n",
    "\n",
    "# Verify keys are set\n",
    "if \"OPENAI_API_KEY\" in os.environ and \"TAVILY_API_KEY\" in os.environ:\n",
    "    print(\"âœ“ API keys are configured!\")\n",
    "else:\n",
    "    print(\"âš  Warning: Please set your API keys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize Components\n",
    "\n",
    "For deep agents, we'll use:\n",
    "- A more advanced LLM (GPT-4)\n",
    "- Memory to maintain conversation context\n",
    "- Tools for external interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0.7,  # Slightly higher temperature for more creative responses\n",
    ")\n",
    "\n",
    "# Get tools\n",
    "search_tool = get_tavily_search_tool(max_results=5, search_depth=\"advanced\")\n",
    "tools = [search_tool]\n",
    "\n",
    "print(f\"âœ“ LLM initialized: {llm.model_name}\")\n",
    "print(f\"âœ“ Tools configured: {[tool.name for tool in tools]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Agent with Memory\n",
    "\n",
    "Memory allows the agent to remember previous interactions and maintain context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create conversation memory\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    "    output_key=\"output\"\n",
    ")\n",
    "\n",
    "# Create a custom prompt with memory placeholder\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=\"\"\"You are a helpful AI assistant with access to web search.\n",
    "    You can search for information, answer questions, and help with various tasks.\n",
    "    Use the available tools when needed to provide accurate, up-to-date information.\n",
    "    \n",
    "    When solving complex problems:\n",
    "    1. Break them down into smaller steps\n",
    "    2. Search for information as needed\n",
    "    3. Synthesize findings into a coherent answer\n",
    "    4. Reflect on whether your answer fully addresses the question\n",
    "    \"\"\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])\n",
    "\n",
    "# Create the agent with memory\n",
    "agent = create_openai_functions_agent(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "# Create agent executor with memory\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    max_iterations=15  # Allow more iterations for complex tasks\n",
    ")\n",
    "\n",
    "print(\"âœ“ Deep agent with memory created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Example 1: Multi-Turn Conversation\n",
    "\n",
    "The agent can maintain context across multiple queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First query\n",
    "result1 = agent_executor.invoke({\n",
    "    \"input\": \"What is Retrieval-Augmented Generation (RAG)?\"\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANSWER 1:\")\n",
    "print(\"=\"*80)\n",
    "print(result1[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow-up query (uses context from previous conversation)\n",
    "result2 = agent_executor.invoke({\n",
    "    \"input\": \"What are some popular frameworks for implementing it?\"\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANSWER 2:\")\n",
    "print(\"=\"*80)\n",
    "print(result2[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another follow-up\n",
    "result3 = agent_executor.invoke({\n",
    "    \"input\": \"Can you give me a code example using one of those frameworks?\"\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANSWER 3:\")\n",
    "print(\"=\"*80)\n",
    "print(result3[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. View Conversation History\n",
    "\n",
    "Let's examine what the agent remembers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check conversation history\n",
    "print(\"Conversation History:\")\n",
    "print(\"=\"*80)\n",
    "for message in memory.chat_memory.messages:\n",
    "    if isinstance(message, HumanMessage):\n",
    "        print(f\"\\nðŸ‘¤ Human: {message.content}\")\n",
    "    elif isinstance(message, AIMessage):\n",
    "        print(f\"\\nðŸ¤– AI: {message.content[:200]}...\")  # Show first 200 chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Example 2: Complex Problem Decomposition\n",
    "\n",
    "Deep agents can break down complex problems into manageable steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear memory for a fresh start\n",
    "memory.clear()\n",
    "\n",
    "# Complex query requiring multiple steps\n",
    "complex_query = \"\"\"I want to build a chatbot for customer service. \n",
    "Can you help me understand:\n",
    "1. What technologies I should use\n",
    "2. The main challenges I'll face\n",
    "3. Best practices for implementation\n",
    "\"\"\"\n",
    "\n",
    "result = agent_executor.invoke({\"input\": complex_query})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL ANSWER:\")\n",
    "print(\"=\"*80)\n",
    "print(result[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Example 3: Research and Synthesis\n",
    "\n",
    "The agent can gather information from multiple sources and synthesize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear memory\n",
    "memory.clear()\n",
    "\n",
    "# Research query\n",
    "research_query = \"\"\"Compare LangChain, LlamaIndex, and Haystack for building RAG applications.\n",
    "Which one would you recommend for a beginner and why?\n",
    "\"\"\"\n",
    "\n",
    "result = agent_executor.invoke({\"input\": research_query})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL ANSWER:\")\n",
    "print(\"=\"*80)\n",
    "print(result[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Example 4: Self-Reflection and Correction\n",
    "\n",
    "Deep agents can reflect on their answers and provide corrections if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear memory\n",
    "memory.clear()\n",
    "\n",
    "# Initial query\n",
    "result1 = agent_executor.invoke({\n",
    "    \"input\": \"What are the main components of a typical LLM application?\"\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INITIAL ANSWER:\")\n",
    "print(\"=\"*80)\n",
    "print(result1[\"output\"])\n",
    "\n",
    "# Ask for reflection\n",
    "result2 = agent_executor.invoke({\n",
    "    \"input\": \"Did you miss anything important? Please review and add any missing components.\"\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"REFLECTED ANSWER:\")\n",
    "print(\"=\"*80)\n",
    "print(result2[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Advanced: Creating a Planning Agent\n",
    "\n",
    "Deep agents can create and execute plans for complex tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear memory\n",
    "memory.clear()\n",
    "\n",
    "# Planning prompt\n",
    "planning_query = \"\"\"I want to create a blog post about 'The Future of AI in Healthcare'.\n",
    "Please create a detailed plan including:\n",
    "1. Key topics to research\n",
    "2. Structure of the blog post\n",
    "3. Important points to cover\n",
    "\"\"\"\n",
    "\n",
    "result = agent_executor.invoke({\"input\": planning_query})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PLAN:\")\n",
    "print(\"=\"*80)\n",
    "print(result[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the first step of the plan\n",
    "result = agent_executor.invoke({\n",
    "    \"input\": \"Now, let's execute step 1. Research the latest developments in AI for healthcare.\"\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESEARCH RESULTS:\")\n",
    "print(\"=\"*80)\n",
    "print(result[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Understanding Deep Agent Architecture\n",
    "\n",
    "Deep agents differ from basic ReAct agents in several ways:\n",
    "\n",
    "### Memory\n",
    "- Maintains conversation history\n",
    "- Can reference previous interactions\n",
    "- Builds context over time\n",
    "\n",
    "### Planning\n",
    "- Can decompose complex tasks\n",
    "- Creates multi-step plans\n",
    "- Adjusts plans based on results\n",
    "\n",
    "### Reflection\n",
    "- Reviews own outputs\n",
    "- Identifies gaps or errors\n",
    "- Self-corrects when needed\n",
    "\n",
    "### Tool Use\n",
    "- Strategic tool selection\n",
    "- Chained tool usage\n",
    "- Result synthesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Custom Query Playground\n",
    "\n",
    "Try your own complex queries!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear memory for fresh start\n",
    "memory.clear()\n",
    "\n",
    "# Your custom query here\n",
    "custom_query = \"\"\"Help me understand how to build a production-ready RAG system.\n",
    "What are the key considerations?\n",
    "\"\"\"\n",
    "\n",
    "result = agent_executor.invoke({\"input\": custom_query})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANSWER:\")\n",
    "print(\"=\"*80)\n",
    "print(result[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "- âœ“ How to create deep agents with memory\n",
    "- âœ“ Managing multi-turn conversations\n",
    "- âœ“ Decomposing complex problems\n",
    "- âœ“ Implementing self-reflection\n",
    "- âœ“ Creating planning agents\n",
    "\n",
    "## Key Differences: ReAct vs Deep Agents\n",
    "\n",
    "| Feature | ReAct Agent | Deep Agent |\n",
    "|---------|-------------|------------|\n",
    "| Memory | No | Yes |\n",
    "| Context | Single query | Multi-turn |\n",
    "| Planning | Basic | Advanced |\n",
    "| Reflection | No | Yes |\n",
    "| Complexity | Simple tasks | Complex workflows |\n",
    "\n",
    "## Next Steps\n",
    "- Implement custom memory types (e.g., vector store memory)\n",
    "- Add more specialized tools\n",
    "- Create agent chains for workflows\n",
    "- Experiment with different LLM parameters\n",
    "- Build domain-specific agents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
