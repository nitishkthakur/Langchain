{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReAct Agent with LangChain\n",
    "\n",
    "This notebook demonstrates how to create and use a ReAct (Reasoning and Acting) agent with LangChain.\n",
    "\n",
    "ReAct agents combine reasoning and acting by allowing the LLM to:\n",
    "1. **Reason** about what action to take\n",
    "2. **Act** by calling tools\n",
    "3. **Observe** the results\n",
    "4. Repeat until the task is complete\n",
    "\n",
    "## What You'll Learn:\n",
    "- Setting up a ReAct agent\n",
    "- Integrating tools (Tavily Search)\n",
    "- Running agent workflows\n",
    "- Understanding agent decision-making process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain import hub\n",
    "\n",
    "# Import our custom Tavily search tool\n",
    "from tools.tavily_search import get_tavily_search_tool\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"✓ Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set Up API Keys\n",
    "\n",
    "You'll need:\n",
    "- OpenAI API key (for the LLM)\n",
    "- Tavily API key (for web search)\n",
    "\n",
    "Set these as environment variables or in a `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and set your API keys if not using .env file\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\"\n",
    "# os.environ[\"TAVILY_API_KEY\"] = \"your-tavily-api-key\"\n",
    "\n",
    "# Verify keys are set\n",
    "if \"OPENAI_API_KEY\" in os.environ and \"TAVILY_API_KEY\" in os.environ:\n",
    "    print(\"✓ API keys are configured!\")\n",
    "else:\n",
    "    print(\"⚠ Warning: Please set your API keys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize the LLM\n",
    "\n",
    "We'll use OpenAI's GPT-4 model as our reasoning engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0,  # Lower temperature for more consistent reasoning\n",
    ")\n",
    "\n",
    "print(f\"✓ LLM initialized: {llm.model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Set Up Tools\n",
    "\n",
    "Tools are the functions/APIs that the agent can use to interact with the world.\n",
    "We'll use the Tavily search tool to enable web searching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Tavily search tool\n",
    "search_tool = get_tavily_search_tool(\n",
    "    max_results=5,\n",
    "    search_depth=\"advanced\"\n",
    ")\n",
    "\n",
    "# Create tools list\n",
    "tools = [search_tool]\n",
    "\n",
    "print(f\"✓ Tools configured: {[tool.name for tool in tools]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create the ReAct Agent\n",
    "\n",
    "The ReAct agent uses a specific prompt template that guides the LLM to:\n",
    "- Think through problems step-by-step\n",
    "- Decide which tools to use\n",
    "- Process observations from tool outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the ReAct prompt template from LangChain Hub\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "\n",
    "# Create the ReAct agent\n",
    "agent = create_react_agent(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "# Create an agent executor (manages the agent's execution)\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,  # Show the agent's reasoning process\n",
    "    handle_parsing_errors=True,  # Handle any parsing errors gracefully\n",
    "    max_iterations=10  # Prevent infinite loops\n",
    ")\n",
    "\n",
    "print(\"✓ ReAct agent created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Example 1: Simple Information Retrieval\n",
    "\n",
    "Let's ask the agent to find current information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the agent with a query\n",
    "result = agent_executor.invoke({\n",
    "    \"input\": \"What are the latest developments in artificial intelligence in 2024?\"\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL ANSWER:\")\n",
    "print(\"=\"*80)\n",
    "print(result[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Example 2: Multi-Step Reasoning\n",
    "\n",
    "Now let's try a more complex query that requires multiple reasoning steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex query requiring research and synthesis\n",
    "result = agent_executor.invoke({\n",
    "    \"input\": \"Who is the current CEO of OpenAI and what is their background?\"\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL ANSWER:\")\n",
    "print(\"=\"*80)\n",
    "print(result[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Example 3: Comparative Analysis\n",
    "\n",
    "The agent can perform comparative analysis by gathering multiple pieces of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparative query\n",
    "result = agent_executor.invoke({\n",
    "    \"input\": \"Compare the main features of GPT-4 and Claude 3. What are the key differences?\"\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL ANSWER:\")\n",
    "print(\"=\"*80)\n",
    "print(result[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Understanding the ReAct Loop\n",
    "\n",
    "The ReAct agent follows this pattern:\n",
    "\n",
    "```\n",
    "Thought: I need to find information about X\n",
    "Action: tavily_search\n",
    "Action Input: \"X latest information\"\n",
    "Observation: [Search results]\n",
    "Thought: Based on the results, I can answer...\n",
    "Final Answer: [Agent's response]\n",
    "```\n",
    "\n",
    "This loop continues until the agent determines it has enough information to provide a final answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Custom Query\n",
    "\n",
    "Try your own query!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your custom query here\n",
    "custom_query = \"What is LangChain and how is it used in AI applications?\"\n",
    "\n",
    "result = agent_executor.invoke({\"input\": custom_query})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL ANSWER:\")\n",
    "print(\"=\"*80)\n",
    "print(result[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "- ✓ How to set up a ReAct agent with LangChain\n",
    "- ✓ How to integrate tools (Tavily search) with agents\n",
    "- ✓ How the ReAct reasoning loop works\n",
    "- ✓ How to use agents for information retrieval and analysis\n",
    "\n",
    "## Next Steps\n",
    "- Explore adding more tools to the agent\n",
    "- Try different LLM models\n",
    "- Experiment with custom prompts\n",
    "- Check out `01.deep_agents_basic.ipynb` for more advanced agent patterns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
